{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "# Load Data\n",
    "spotify_data = pd.read_csv('cleaned_spotify_data.csv')\n",
    "user_profiles = pd.read_csv('cleaned_user_profiles.csv')\n",
    "user_profiles = user_profiles.sample(frac = 0.05, random_state = 42)\n",
    "features_to_drop = ['key', 'mode', 'duration_ms', 'liveness']\n",
    "#check if the features are in the dataframe before dropping them\n",
    "spotify_data = spotify_data.drop(features_to_drop, axis = 1, errors = 'ignore')\n",
    "user_profiles = user_profiles.drop(features_to_drop, axis = 1, errors = 'ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data = spotify_data.sample(frac = 0.25, random_state = 42)\n",
    "\n",
    "features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'valence', 'tempo']\n",
    "spotify_features = spotify_data[features]\n",
    "user_features = user_profiles[features]\n",
    "\n",
    "# Data Scaling\n",
    "scaler = StandardScaler()\n",
    "spotify_features_scaled = scaler.fit_transform(spotify_features)\n",
    "spotify_features_scaled = spotify_features_scaled\n",
    "user_features_scaled = scaler.transform(user_features)\n",
    "user_features_scaled = user_features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30056</th>\n",
       "      <td>I Miss You</td>\n",
       "      <td>Jeriqo</td>\n",
       "      <td>edm</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.789</td>\n",
       "      <td>-7.717</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>174.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11827</th>\n",
       "      <td>Who Are You</td>\n",
       "      <td>The Who</td>\n",
       "      <td>rock</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.661</td>\n",
       "      <td>-11.405</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>0.265000</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>156.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23571</th>\n",
       "      <td>Happy</td>\n",
       "      <td>The Beef Seeds</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.758</td>\n",
       "      <td>-5.204</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>86.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14741</th>\n",
       "      <td>ONE</td>\n",
       "      <td>Rev Theory</td>\n",
       "      <td>rock</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.966</td>\n",
       "      <td>-2.352</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>90.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>Palace/Curse</td>\n",
       "      <td>The Internet</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-8.212</td>\n",
       "      <td>0.3230</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>67.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>Captain Save a Hoe (feat. The Click, D-Shot, B...</td>\n",
       "      <td>E-40</td>\n",
       "      <td>rap</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-12.235</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5630</td>\n",
       "      <td>166.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>Macarena - Bayside Boys Remix</td>\n",
       "      <td>Los Del Rio</td>\n",
       "      <td>pop</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.909</td>\n",
       "      <td>-6.032</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>103.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23613</th>\n",
       "      <td>How Crazy Is That</td>\n",
       "      <td>Derrick Ryan</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-12.198</td>\n",
       "      <td>0.0754</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>123.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>Song To The Siren (Remastered)</td>\n",
       "      <td>This Mortal Coil</td>\n",
       "      <td>pop</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-12.598</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>128.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30005</th>\n",
       "      <td>Where Is the Love (Wave Remix)</td>\n",
       "      <td>Alex Martura</td>\n",
       "      <td>edm</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.645</td>\n",
       "      <td>-9.815</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>115.980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8208 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   track            artist  \\\n",
       "30056                                         I Miss You            Jeriqo   \n",
       "11827                                        Who Are You           The Who   \n",
       "23571                                              Happy    The Beef Seeds   \n",
       "14741                                                ONE        Rev Theory   \n",
       "25570                                       Palace/Curse      The Internet   \n",
       "...                                                  ...               ...   \n",
       "7836   Captain Save a Hoe (feat. The Click, D-Shot, B...              E-40   \n",
       "764                        Macarena - Bayside Boys Remix       Los Del Rio   \n",
       "23613                                  How Crazy Is That      Derrick Ryan   \n",
       "3422                      Song To The Siren (Remastered)  This Mortal Coil   \n",
       "30005                     Where Is the Love (Wave Remix)      Alex Martura   \n",
       "\n",
       "      genre  danceability  energy  loudness  speechiness  acousticness  \\\n",
       "30056   edm         0.520   0.789    -7.717       0.0432      0.004910   \n",
       "11827  rock         0.651   0.661   -11.405       0.0511      0.265000   \n",
       "23571   r&b         0.640   0.758    -5.204       0.1600      0.665000   \n",
       "14741  rock         0.398   0.966    -2.352       0.0453      0.000006   \n",
       "25570   r&b         0.447   0.625    -8.212       0.3230      0.035100   \n",
       "...     ...           ...     ...       ...          ...           ...   \n",
       "7836    rap         0.753   0.514   -12.235       0.2600      0.061200   \n",
       "764     pop         0.746   0.909    -6.032       0.0580      0.206000   \n",
       "23613   r&b         0.782   0.326   -12.198       0.0754      0.058500   \n",
       "3422    pop         0.216   0.240   -12.598       0.0406      0.843000   \n",
       "30005   edm         0.793   0.645    -9.815       0.0443      0.531000   \n",
       "\n",
       "       instrumentalness  valence    tempo  \n",
       "30056          0.000013   0.4150  174.026  \n",
       "11827          0.003130   0.4890  156.371  \n",
       "23571          0.000000   0.9320   86.529  \n",
       "14741          0.000000   0.5200   90.016  \n",
       "25570          0.000727   0.2610   67.104  \n",
       "...                 ...      ...      ...  \n",
       "7836           0.000000   0.5630  166.015  \n",
       "764            0.000002   0.9620  103.189  \n",
       "23613          0.000009   0.1970  123.940  \n",
       "3422           0.000006   0.0875  128.679  \n",
       "30005          0.000210   0.3650  115.980  \n",
       "\n",
       "[8208 rows x 11 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34c5b62e9510fbf18271381aba7cf683\n"
     ]
    }
   ],
   "source": [
    "user_index = 4  # Change based on your user profile index\n",
    "user_id = user_profiles.iloc[user_index]['userid']\n",
    "\n",
    "print(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch processing... Total users: 647, Total songs: 8208\n",
      "Processing batch from user index 0 to 99\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (647, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 100 to 199\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (647, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 200 to 299\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (647, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 300 to 399\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (647, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 400 to 499\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (647, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 500 to 599\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (647, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 600 to 646\n",
      "Feature similarity calculated for batch. Shape: (47, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (647, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Data prepared for neural network input.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gc  # Garbage Collector interface\n",
    "\n",
    "def calculate_interaction_batch(user_features_scaled, spotify_features_scaled, user_profiles, spotify_data, batch_size=100):\n",
    "    num_users = user_profiles.shape[0]\n",
    "    num_songs = spotify_data.shape[0]\n",
    "    interaction_scores = np.zeros((num_users, num_songs))\n",
    "    \n",
    "    print(f\"Starting batch processing... Total users: {num_users}, Total songs: {num_songs}\")\n",
    "\n",
    "    # Batch processing\n",
    "    for start_idx in range(0, num_users, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_users)\n",
    "        print(f\"Processing batch from user index {start_idx} to {end_idx - 1}\")\n",
    "\n",
    "        # Calculate distances and similarity scores for the batch\n",
    "        user_batch = user_features_scaled[start_idx:end_idx]\n",
    "        distances = np.sqrt(((user_batch[:, np.newaxis, :] - spotify_features_scaled[np.newaxis, :, :]) ** 2).sum(axis=2))\n",
    "        feature_similarity = np.exp(-distances)\n",
    "        print(f\"Feature similarity calculated for batch. Shape: {feature_similarity.shape}\")\n",
    "\n",
    "        # Calculate genre and artist similarity\n",
    "        genre_similarity = (user_profiles['genre'].values[start_idx:end_idx, np.newaxis] == spotify_data['genre'].values[np.newaxis, :]).astype(int)\n",
    "        artist_similarity = (user_profiles['artist'].values[start_idx:end_idx, np.newaxis] == spotify_data['artist'].values[np.newaxis, :]).astype(int)\n",
    "        print(f\"Genre and artist similarity calculated for batch.\")\n",
    "\n",
    "        # Calculate composite score for the batch\n",
    "        interaction_scores[start_idx:end_idx] = 0.4 * feature_similarity + 0.55 * genre_similarity + 0.05 * artist_similarity\n",
    "        print(f\"Interaction scores updated for batch. Current shape of scores array: {interaction_scores.shape}\")\n",
    "\n",
    "        # Explicitly call garbage collection\n",
    "        gc.collect()\n",
    "        print(f\"Garbage collection triggered after processing batch.\")\n",
    "\n",
    "    return interaction_scores\n",
    "\n",
    "# Usage example with debugging\n",
    "interaction_scores = calculate_interaction_batch(user_features_scaled, spotify_features_scaled, user_profiles, spotify_data, batch_size=100)\n",
    "interaction_threshold = np.percentile(interaction_scores, 75)  # top 25% as positive interaction\n",
    "interaction = (interaction_scores >= interaction_threshold).astype(int)\n",
    "\n",
    "# Flatten interaction matrix and features for neural network input\n",
    "X = spotify_features_scaled.repeat(len(user_profiles), axis=0)\n",
    "y = interaction.flatten()\n",
    "print(\"Data prepared for neural network input.\")\n",
    "\n",
    "# def calculate_interaction_vectorized(user_features_scaled, spotify_features_scaled, user_profiles, spotify_data):\n",
    "#     # Euclidean distances\n",
    "#     distances = np.sqrt(((user_features_scaled[:, np.newaxis, :] - spotify_features_scaled[np.newaxis, :, :]) ** 2).sum(axis=2))\n",
    "#     print(distances)\n",
    "#     # Scale distances into similarity scores (exp(-distance))\n",
    "#     feature_similarity = np.exp(-distances)\n",
    "#     print(feature_similarity)\n",
    "#     # Genre and artist similarity (binary 0 or 1)\n",
    "#     genre_similarity = (user_profiles['genre'].values[:, np.newaxis] == spotify_data['genre'].values[np.newaxis, :]).astype(int)\n",
    "#     print(genre_similarity)\n",
    "#     artist_similarity = (user_profiles['artist'].values[:, np.newaxis] == spotify_data['artist'].values[np.newaxis, :]).astype(int)\n",
    "#     print(artist_similarity)\n",
    "    \n",
    "#     # Composite score\n",
    "#     interaction_scores = 0.7 * feature_similarity + 0.2 * genre_similarity + 0.1 * artist_similarity\n",
    "#     print(interaction_scores)\n",
    "#     return interaction_scores\n",
    "\n",
    "# # Generate interaction scores\n",
    "# interaction_scores = calculate_interaction_vectorized(user_features_scaled, spotify_features_scaled, user_profiles, spotify_data)\n",
    "# interaction_threshold = np.percentile(interaction_scores, 75)  # top 25% as positive interaction\n",
    "# interaction = (interaction_scores >= interaction_threshold).astype(int)\n",
    "\n",
    "# # Flatten interaction matrix and features for neural network input\n",
    "# X = spotify_features_scaled.repeat(len(user_profiles), axis=0)\n",
    "# y = interaction.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "Data split into training and testing sets. Training model...\n"
     ]
    }
   ],
   "source": [
    "# Neural network setup with Dropout\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=len(features)),\n",
    "    Dropout(0.1),  # Dropout to prevent overfitting\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Output a score between 0 and 1\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"Model compiled.\")\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data split into training and testing sets. Training model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m132765/132765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 1ms/step - accuracy: 0.7498 - loss: 0.5634 - val_accuracy: 0.7497 - val_loss: 0.5627\n",
      "Epoch 2/10\n",
      "\u001b[1m132765/132765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 1ms/step - accuracy: 0.7499 - loss: 0.5625 - val_accuracy: 0.7497 - val_loss: 0.5627\n",
      "Epoch 3/10\n",
      "\u001b[1m132765/132765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 1ms/step - accuracy: 0.7499 - loss: 0.5624 - val_accuracy: 0.7497 - val_loss: 0.5627\n",
      "Epoch 4/10\n",
      "\u001b[1m132765/132765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 1ms/step - accuracy: 0.7499 - loss: 0.5624 - val_accuracy: 0.7497 - val_loss: 0.5627\n",
      "Epoch 5/10\n",
      "\u001b[1m132765/132765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 1ms/step - accuracy: 0.7502 - loss: 0.5621 - val_accuracy: 0.7497 - val_loss: 0.5627\n",
      "Epoch 6/10\n",
      "\u001b[1m132765/132765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 1ms/step - accuracy: 0.7501 - loss: 0.5622 - val_accuracy: 0.7497 - val_loss: 0.5627\n",
      "Epoch 7/10\n",
      "\u001b[1m132765/132765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 1ms/step - accuracy: 0.7500 - loss: 0.5623 - val_accuracy: 0.7497 - val_loss: 0.5627\n",
      "Epoch 8/10\n",
      "\u001b[1m132765/132765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 1ms/step - accuracy: 0.7502 - loss: 0.5621 - val_accuracy: 0.7497 - val_loss: 0.5627\n",
      "Epoch 9/10\n",
      "\u001b[1m132765/132765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 1ms/step - accuracy: 0.7506 - loss: 0.5617 - val_accuracy: 0.7497 - val_loss: 0.5627\n",
      "Epoch 10/10\n",
      "\u001b[1m132765/132765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 1ms/step - accuracy: 0.7498 - loss: 0.5625 - val_accuracy: 0.7497 - val_loss: 0.5627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4041"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "prediction complete and memory cleared.\n"
     ]
    }
   ],
   "source": [
    "# Predict interaction scores for all songs using batch prediction\n",
    "predicted_scores = model.predict(spotify_features_scaled).flatten()\n",
    "spotify_data['predicted_interaction'] = predicted_scores\n",
    "gc.collect()  # Clear memory of no longer needed large objects\n",
    "print(\"prediction complete and memory cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN model set up.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    }
   ],
   "source": [
    "# k-NN model using enhanced features\n",
    "features_with_score = features + ['predicted_interaction']\n",
    "knn = NearestNeighbors(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(spotify_data[features_with_score])\n",
    "print(\"k-NN model set up.\")\n",
    "\n",
    "user_index = 4  # Change based on your user profile index\n",
    "user_id = user_profiles.iloc[user_index]['userid']\n",
    "user_top_genre = user_profiles.iloc[user_index]['genre']\n",
    "user_feature_vector = user_features_scaled[user_index].reshape(1, -1)\n",
    "user_predicted_score = model.predict(user_feature_vector).flatten()[0]\n",
    "query_vector = np.append(user_feature_vector, user_predicted_score).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Songs for User: 34c5b62e9510fbf18271381aba7cf683, Top Genre: rock\n",
      "                                   track             artist  genre\n",
      "11363              Hi, How're You Doin'?   DREAMS COME TRUE   rock\n",
      "13764  Still Crazy After All These Years         Paul Simon   rock\n",
      "6502                         cold nights             itssvd    rap\n",
      "19325                               Culo            Pitbull  latin\n",
      "22513                       Heard a Word  Michelle Williams    r&b\n",
      "\u001b[1m   59/33192\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 871us/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33192/33192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 793us/step\n",
      "RMSE for neural network predictions: 0.4332059377779928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Finding top 5 nearest songs\n",
    "distances, indices = knn.kneighbors(query_vector)\n",
    "recommended_songs = spotify_data.iloc[indices[0]]\n",
    "\n",
    "# Output recommended songs\n",
    "print(f\"Recommended Songs for User: {user_id}, Top Genre: {user_top_genre}\")\n",
    "print(recommended_songs[['track', 'artist', 'genre']])\n",
    "\n",
    "# Validation\n",
    "predicted_interactions = model.predict(X_test).flatten()\n",
    "rmse = mean_squared_error(y_test, predicted_interactions, squared=False)\n",
    "print(\"RMSE for neural network predictions:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict interaction scores for all songs\n",
    "\n",
    "# print(\"starting prediction\") \n",
    "\n",
    "# predicted_scores = model.predict(spotify_features_scaled).flatten()\n",
    "# spotify_data['predicted_interaction'] = predicted_scores\n",
    "\n",
    "# # k-NN model using enhanced features\n",
    "# features_with_score = features + ['predicted_interaction']\n",
    "# knn = NearestNeighbors(n_neighbors=5, metric='euclidean')\n",
    "# knn.fit(spotify_data[features_with_score])\n",
    "\n",
    "# # Example user query using k-NN with neural network outputs\n",
    "# user_index = 3  # Change based on your user profile index\n",
    "# user_id = user_profiles.iloc[user_index]['userid']\n",
    "# user_top_genre = user_profiles.iloc[user_index]['genre']\n",
    "# user_feature_vector = user_features_scaled[user_index].reshape(1, -1)\n",
    "# user_predicted_score = model.predict(user_feature_vector).flatten()[0]\n",
    "# query_vector = np.append(user_feature_vector, user_predicted_score).reshape(1, -1)\n",
    "\n",
    "# # Finding top 5 nearest songs\n",
    "# distances, indices = knn.kneighbors(query_vector)\n",
    "# recommended_songs = spotify_data.iloc[indices[0]]\n",
    "\n",
    "# # Output recommended songs\n",
    "# print(f\"Recommended Songs for User: {user_id}, Top Genre: {user_top_genre}\")\n",
    "# print(recommended_songs[['track', 'artist', 'genre']])\n",
    "\n",
    "# # Validation\n",
    "# predicted_interactions = model.predict(X_test).flatten()\n",
    "# rmse = mean_squared_error(y_test, predicted_interactions, squared=False)\n",
    "# print(\"RMSE for neural network predictions:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['feature1', 'feature2', 'feature3'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming you have selected three features from your dataset for the plot\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Let's say 'feature1', 'feature2', and 'feature3' are the columns you're interested in\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Extract these features for the nearest neighbors\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m nn_features \u001b[38;5;241m=\u001b[39m \u001b[43mspotify_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeature1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeature2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeature3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Extract the query user's features (assuming the query_vector includes these three features)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m query_features \u001b[38;5;241m=\u001b[39m query_vector[\u001b[38;5;241m0\u001b[39m, :\u001b[38;5;241m3\u001b[39m]  \u001b[38;5;66;03m# Make sure this slicing matches the feature indices\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['feature1', 'feature2', 'feature3'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Assuming you have selected three features from your dataset for the plot\n",
    "# Let's say 'feature1', 'feature2', and 'feature3' are the columns you're interested in\n",
    "\n",
    "# Extract these features for the nearest neighbors\n",
    "nn_features = spotify_data.iloc[indices[0]][['feature1', 'feature2', 'feature3']]\n",
    "\n",
    "# Extract the query user's features (assuming the query_vector includes these three features)\n",
    "query_features = query_vector[0, :3]  # Make sure this slicing matches the feature indices\n",
    "\n",
    "# Create a scatter plot for the neighbors\n",
    "trace_neighbors = go.Scatter3d(\n",
    "    x=nn_features['feature1'],\n",
    "    y=nn_features['feature2'],\n",
    "    z=nn_features['feature3'],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color='blue', opacity=0.8),\n",
    "    name='Nearest Neighbors'\n",
    ")\n",
    "\n",
    "# Add the query user's point\n",
    "trace_query = go.Scatter3d(\n",
    "    x=[query_features[0]],\n",
    "    y=[query_features[1]],\n",
    "    z=[query_features[2]],\n",
    "    mode='markers',\n",
    "    marker=dict(size=10, color='red', opacity=1),\n",
    "    name='Query User'\n",
    ")\n",
    "\n",
    "# Define the layout and plot everything\n",
    "layout = go.Layout(\n",
    "    title='3D Scatter Plot of User and Nearest Neighbors in Feature Space',\n",
    "    margin=dict(l=0, r=0, b=0, t=0),\n",
    "    scene=dict(\n",
    "        xaxis_title='Feature 1',\n",
    "        yaxis_title='Feature 2',\n",
    "        zaxis_title='Feature 3'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[trace_neighbors, trace_query], layout=layout)\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
