{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "# Load Data\n",
    "spotify_data = pd.read_csv('cleaned_spotify_data.csv')\n",
    "user_profiles = pd.read_csv('cleaned_user_profiles.csv')\n",
    "user_profiles = user_profiles.sample(frac = 0.1, random_state = 42)\n",
    "spotify_data = spotify_data.sample(frac = 0.25, random_state = 42)\n",
    "\n",
    "features = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "spotify_features = spotify_data[features]\n",
    "user_features = user_profiles[features]\n",
    "\n",
    "# Data Scaling\n",
    "scaler = StandardScaler()\n",
    "spotify_features_scaled = scaler.fit_transform(spotify_features)\n",
    "spotify_features_scaled = spotify_features_scaled\n",
    "user_features_scaled = scaler.transform(user_features)\n",
    "user_features_scaled = user_features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "# Load Data\n",
    "spotify_data = pd.read_csv('cleaned_spotify_data.csv')\n",
    "user_profiles = pd.read_csv('cleaned_user_profiles.csv')\n",
    "user_profiles = user_profiles.sample(frac = 0.1, random_state = 42)\n",
    "spotify_data = spotify_data.sample(frac = 0.25, random_state = 42)\n",
    "\n",
    "features = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "spotify_features = spotify_data[features]\n",
    "user_features = user_profiles[features]\n",
    "\n",
    "# Data Scaling\n",
    "scaler = StandardScaler()\n",
    "spotify_features_scaled = scaler.fit_transform(spotify_features)\n",
    "spotify_features_scaled = spotify_features_scaled\n",
    "user_features_scaled = scaler.transform(user_features)\n",
    "user_features_scaled = user_features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30056</th>\n",
       "      <td>I Miss You</td>\n",
       "      <td>Jeriqo</td>\n",
       "      <td>edm</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.717</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>174.026</td>\n",
       "      <td>216347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11827</th>\n",
       "      <td>Who Are You</td>\n",
       "      <td>The Who</td>\n",
       "      <td>rock</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.661</td>\n",
       "      <td>9</td>\n",
       "      <td>-11.405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>0.265000</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>156.371</td>\n",
       "      <td>378707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23571</th>\n",
       "      <td>Happy</td>\n",
       "      <td>The Beef Seeds</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.758</td>\n",
       "      <td>10</td>\n",
       "      <td>-5.204</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>86.529</td>\n",
       "      <td>218044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14741</th>\n",
       "      <td>ONE</td>\n",
       "      <td>Rev Theory</td>\n",
       "      <td>rock</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.966</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.352</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>90.016</td>\n",
       "      <td>208196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>Palace/Curse</td>\n",
       "      <td>The Internet</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.625</td>\n",
       "      <td>10</td>\n",
       "      <td>-8.212</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3230</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>67.104</td>\n",
       "      <td>440013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>Captain Save a Hoe (feat. The Click, D-Shot, B...</td>\n",
       "      <td>E-40</td>\n",
       "      <td>rap</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.514</td>\n",
       "      <td>7</td>\n",
       "      <td>-12.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2920</td>\n",
       "      <td>0.5630</td>\n",
       "      <td>166.015</td>\n",
       "      <td>287600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>Macarena - Bayside Boys Remix</td>\n",
       "      <td>Los Del Rio</td>\n",
       "      <td>pop</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.909</td>\n",
       "      <td>11</td>\n",
       "      <td>-6.032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>103.189</td>\n",
       "      <td>222027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23613</th>\n",
       "      <td>How Crazy Is That</td>\n",
       "      <td>Derrick Ryan</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.326</td>\n",
       "      <td>6</td>\n",
       "      <td>-12.198</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0754</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>123.940</td>\n",
       "      <td>193548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>Song To The Siren (Remastered)</td>\n",
       "      <td>This Mortal Coil</td>\n",
       "      <td>pop</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.240</td>\n",
       "      <td>10</td>\n",
       "      <td>-12.598</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>128.679</td>\n",
       "      <td>211093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30005</th>\n",
       "      <td>Where Is the Love (Wave Remix)</td>\n",
       "      <td>Alex Martura</td>\n",
       "      <td>edm</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.645</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.815</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>115.980</td>\n",
       "      <td>184138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8208 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   track            artist  \\\n",
       "30056                                         I Miss You            Jeriqo   \n",
       "11827                                        Who Are You           The Who   \n",
       "23571                                              Happy    The Beef Seeds   \n",
       "14741                                                ONE        Rev Theory   \n",
       "25570                                       Palace/Curse      The Internet   \n",
       "...                                                  ...               ...   \n",
       "7836   Captain Save a Hoe (feat. The Click, D-Shot, B...              E-40   \n",
       "764                        Macarena - Bayside Boys Remix       Los Del Rio   \n",
       "23613                                  How Crazy Is That      Derrick Ryan   \n",
       "3422                      Song To The Siren (Remastered)  This Mortal Coil   \n",
       "30005                     Where Is the Love (Wave Remix)      Alex Martura   \n",
       "\n",
       "      genre  danceability  energy  key  loudness  mode  speechiness  \\\n",
       "30056   edm         0.520   0.789    0    -7.717     1       0.0432   \n",
       "11827  rock         0.651   0.661    9   -11.405     1       0.0511   \n",
       "23571   r&b         0.640   0.758   10    -5.204     1       0.1600   \n",
       "14741  rock         0.398   0.966    4    -2.352     0       0.0453   \n",
       "25570   r&b         0.447   0.625   10    -8.212     0       0.3230   \n",
       "...     ...           ...     ...  ...       ...   ...          ...   \n",
       "7836    rap         0.753   0.514    7   -12.235     1       0.2600   \n",
       "764     pop         0.746   0.909   11    -6.032     1       0.0580   \n",
       "23613   r&b         0.782   0.326    6   -12.198     0       0.0754   \n",
       "3422    pop         0.216   0.240   10   -12.598     1       0.0406   \n",
       "30005   edm         0.793   0.645    2    -9.815     0       0.0443   \n",
       "\n",
       "       acousticness  instrumentalness  liveness  valence    tempo  duration_ms  \n",
       "30056      0.004910          0.000013    0.0816   0.4150  174.026       216347  \n",
       "11827      0.265000          0.003130    0.1060   0.4890  156.371       378707  \n",
       "23571      0.665000          0.000000    0.1270   0.9320   86.529       218044  \n",
       "14741      0.000006          0.000000    0.3030   0.5200   90.016       208196  \n",
       "25570      0.035100          0.000727    0.2430   0.2610   67.104       440013  \n",
       "...             ...               ...       ...      ...      ...          ...  \n",
       "7836       0.061200          0.000000    0.2920   0.5630  166.015       287600  \n",
       "764        0.206000          0.000002    0.0656   0.9620  103.189       222027  \n",
       "23613      0.058500          0.000009    0.1320   0.1970  123.940       193548  \n",
       "3422       0.843000          0.000006    0.1350   0.0875  128.679       211093  \n",
       "30005      0.531000          0.000210    0.1000   0.3650  115.980       184138  \n",
       "\n",
       "[8208 rows x 15 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34c5b62e9510fbf18271381aba7cf683\n"
     ]
    }
   ],
   "source": [
    "user_index = 4  # Change based on your user profile index\n",
    "user_id = user_profiles.iloc[user_index]['userid']\n",
    "\n",
    "print(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch processing... Total users: 1294, Total songs: 8208\n",
      "Processing batch from user index 0 to 99\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 100 to 199\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 200 to 299\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 300 to 399\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 400 to 499\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 500 to 599\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 600 to 699\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 700 to 799\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 800 to 899\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 900 to 999\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 1000 to 1099\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 1100 to 1199\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 1200 to 1293\n",
      "Feature similarity calculated for batch. Shape: (94, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Data prepared for neural network input.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gc  # Garbage Collector interface\n",
    "\n",
    "def calculate_interaction_batch(user_features_scaled, spotify_features_scaled, user_profiles, spotify_data, batch_size=100):\n",
    "    num_users = user_profiles.shape[0]\n",
    "    num_songs = spotify_data.shape[0]\n",
    "    interaction_scores = np.zeros((num_users, num_songs))\n",
    "    \n",
    "    print(f\"Starting batch processing... Total users: {num_users}, Total songs: {num_songs}\")\n",
    "\n",
    "    # Batch processing\n",
    "    for start_idx in range(0, num_users, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_users)\n",
    "        print(f\"Processing batch from user index {start_idx} to {end_idx - 1}\")\n",
    "\n",
    "        # Calculate distances and similarity scores for the batch\n",
    "        user_batch = user_features_scaled[start_idx:end_idx]\n",
    "        distances = np.sqrt(((user_batch[:, np.newaxis, :] - spotify_features_scaled[np.newaxis, :, :]) ** 2).sum(axis=2))\n",
    "        feature_similarity = np.exp(-distances)\n",
    "        print(f\"Feature similarity calculated for batch. Shape: {feature_similarity.shape}\")\n",
    "\n",
    "        # Calculate genre and artist similarity\n",
    "        genre_similarity = (user_profiles['genre'].values[start_idx:end_idx, np.newaxis] == spotify_data['genre'].values[np.newaxis, :]).astype(int)\n",
    "        artist_similarity = (user_profiles['artist'].values[start_idx:end_idx, np.newaxis] == spotify_data['artist'].values[np.newaxis, :]).astype(int)\n",
    "        print(f\"Genre and artist similarity calculated for batch.\")\n",
    "\n",
    "        # Calculate composite score for the batch\n",
    "        interaction_scores[start_idx:end_idx] = 0.7 * feature_similarity + 0.2 * genre_similarity + 0.1 * artist_similarity\n",
    "        print(f\"Interaction scores updated for batch. Current shape of scores array: {interaction_scores.shape}\")\n",
    "\n",
    "        # Explicitly call garbage collection\n",
    "        gc.collect()\n",
    "        print(f\"Garbage collection triggered after processing batch.\")\n",
    "\n",
    "    return interaction_scores\n",
    "\n",
    "# Usage example with debugging\n",
    "interaction_scores = calculate_interaction_batch(user_features_scaled, spotify_features_scaled, user_profiles, spotify_data, batch_size=100)\n",
    "interaction_threshold = np.percentile(interaction_scores, 75)  # top 25% as positive interaction\n",
    "interaction = (interaction_scores >= interaction_threshold).astype(int)\n",
    "\n",
    "# Flatten interaction matrix and features for neural network input\n",
    "X = spotify_features_scaled.repeat(len(user_profiles), axis=0)\n",
    "y = interaction.flatten()\n",
    "print(\"Data prepared for neural network input.\")\n",
    "\n",
    "# def calculate_interaction_vectorized(user_features_scaled, spotify_features_scaled, user_profiles, spotify_data):\n",
    "#     # Euclidean distances\n",
    "#     distances = np.sqrt(((user_features_scaled[:, np.newaxis, :] - spotify_features_scaled[np.newaxis, :, :]) ** 2).sum(axis=2))\n",
    "#     print(distances)\n",
    "#     # Scale distances into similarity scores (exp(-distance))\n",
    "#     feature_similarity = np.exp(-distances)\n",
    "#     print(feature_similarity)\n",
    "#     # Genre and artist similarity (binary 0 or 1)\n",
    "#     genre_similarity = (user_profiles['genre'].values[:, np.newaxis] == spotify_data['genre'].values[np.newaxis, :]).astype(int)\n",
    "#     print(genre_similarity)\n",
    "#     artist_similarity = (user_profiles['artist'].values[:, np.newaxis] == spotify_data['artist'].values[np.newaxis, :]).astype(int)\n",
    "#     print(artist_similarity)\n",
    "    \n",
    "#     # Composite score\n",
    "#     interaction_scores = 0.7 * feature_similarity + 0.2 * genre_similarity + 0.1 * artist_similarity\n",
    "#     print(interaction_scores)\n",
    "#     return interaction_scores\n",
    "\n",
    "# # Generate interaction scores\n",
    "# interaction_scores = calculate_interaction_vectorized(user_features_scaled, spotify_features_scaled, user_profiles, spotify_data)\n",
    "# interaction_threshold = np.percentile(interaction_scores, 75)  # top 25% as positive interaction\n",
    "# interaction = (interaction_scores >= interaction_threshold).astype(int)\n",
    "\n",
    "# # Flatten interaction matrix and features for neural network input\n",
    "# X = spotify_features_scaled.repeat(len(user_profiles), axis=0)\n",
    "# y = interaction.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing sets. Training model...\n"
     ]
    }
   ],
   "source": [
    "# Neural network setup with Dropout\n",
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=len(features), kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.1),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Setting up early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data split into training and testing sets. Training model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 2ms/step - accuracy: 0.7499 - loss: 0.5656 - val_accuracy: 0.7497 - val_loss: 0.5627\n",
      "Epoch 2/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m480s\u001b[0m 2ms/step - accuracy: 0.7502 - loss: 0.5622 - val_accuracy: 0.7497 - val_loss: 0.5626\n",
      "Epoch 3/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 2ms/step - accuracy: 0.7502 - loss: 0.5622 - val_accuracy: 0.7497 - val_loss: 0.5627\n",
      "Epoch 4/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 2ms/step - accuracy: 0.7498 - loss: 0.5626 - val_accuracy: 0.7497 - val_loss: 0.5628\n",
      "Epoch 5/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m650s\u001b[0m 2ms/step - accuracy: 0.7501 - loss: 0.5623 - val_accuracy: 0.7497 - val_loss: 0.5626\n",
      "Epoch 6/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m683s\u001b[0m 3ms/step - accuracy: 0.7502 - loss: 0.5621 - val_accuracy: 0.7497 - val_loss: 0.5628\n",
      "Epoch 7/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m662s\u001b[0m 2ms/step - accuracy: 0.7501 - loss: 0.5623 - val_accuracy: 0.7497 - val_loss: 0.5627\n",
      "Epoch 8/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 2ms/step - accuracy: 0.7500 - loss: 0.5623 - val_accuracy: 0.7497 - val_loss: 0.5626\n",
      "Epoch 9/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 2ms/step - accuracy: 0.7500 - loss: 0.5623 - val_accuracy: 0.7497 - val_loss: 0.5626\n",
      "Epoch 10/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 2ms/step - accuracy: 0.7501 - loss: 0.5623 - val_accuracy: 0.7497 - val_loss: 0.5628\n",
      "Epoch 11/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 2ms/step - accuracy: 0.7503 - loss: 0.5620 - val_accuracy: 0.7497 - val_loss: 0.5626\n",
      "Epoch 12/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m659s\u001b[0m 2ms/step - accuracy: 0.7502 - loss: 0.5622 - val_accuracy: 0.7497 - val_loss: 0.5628\n",
      "Epoch 13/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 2ms/step - accuracy: 0.7500 - loss: 0.5624 - val_accuracy: 0.7497 - val_loss: 0.5626\n",
      "Epoch 14/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 2ms/step - accuracy: 0.7500 - loss: 0.5624 - val_accuracy: 0.7497 - val_loss: 0.5627\n",
      "Epoch 15/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m611s\u001b[0m 2ms/step - accuracy: 0.7499 - loss: 0.5625 - val_accuracy: 0.7497 - val_loss: 0.5627\n",
      "Epoch 16/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m752s\u001b[0m 3ms/step - accuracy: 0.7501 - loss: 0.5623 - val_accuracy: 0.7497 - val_loss: 0.5626\n",
      "Epoch 17/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m752s\u001b[0m 3ms/step - accuracy: 0.7501 - loss: 0.5623 - val_accuracy: 0.7497 - val_loss: 0.5626\n",
      "Epoch 18/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m694s\u001b[0m 3ms/step - accuracy: 0.7504 - loss: 0.5620 - val_accuracy: 0.7497 - val_loss: 0.5626\n",
      "Epoch 19/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m602s\u001b[0m 2ms/step - accuracy: 0.7502 - loss: 0.5622 - val_accuracy: 0.7497 - val_loss: 0.5626\n",
      "Epoch 20/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m607s\u001b[0m 2ms/step - accuracy: 0.7503 - loss: 0.5620 - val_accuracy: 0.7497 - val_loss: 0.5627\n",
      "Epoch 21/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m569s\u001b[0m 2ms/step - accuracy: 0.7501 - loss: 0.5622 - val_accuracy: 0.7497 - val_loss: 0.5626\n",
      "Epoch 22/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 2ms/step - accuracy: 0.7504 - loss: 0.5620 - val_accuracy: 0.7497 - val_loss: 0.5627\n",
      "Epoch 23/50\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m537s\u001b[0m 2ms/step - accuracy: 0.7501 - loss: 0.5622 - val_accuracy: 0.7497 - val_loss: 0.5626\n",
      "Epoch 24/50\n",
      "\u001b[1m254975/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.7499 - loss: 0.5624"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict interaction scores for all songs using batch prediction\n",
    "predicted_scores = model.predict(spotify_features_scaled).flatten()\n",
    "spotify_data['predicted_interaction'] = predicted_scores\n",
    "gc.collect()  # Clear memory of no longer needed large objects\n",
    "print(\"prediction complete and memory cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-NN model using enhanced features\n",
    "features_with_score = features + ['predicted_interaction']\n",
    "knn = NearestNeighbors(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(spotify_data[features_with_score])\n",
    "print(\"k-NN model set up.\")\n",
    "\n",
    "user_index = 3  # Change based on your user profile index\n",
    "user_id = user_profiles.iloc[user_index]['userid']\n",
    "user_top_genre = user_profiles.iloc[user_index]['genre']\n",
    "user_feature_vector = user_features_scaled[user_index].reshape(1, -1)\n",
    "user_predicted_score = model.predict(user_feature_vector).flatten()[0]\n",
    "query_vector = np.append(user_feature_vector, user_predicted_score).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding top 5 nearest songs\n",
    "distances, indices = knn.kneighbors(query_vector)\n",
    "recommended_songs = spotify_data.iloc[indices[0]]\n",
    "\n",
    "# Output recommended songs\n",
    "print(f\"Recommended Songs for User: {user_id}, Top Genre: {user_top_genre}\")\n",
    "print(recommended_songs[['track', 'artist', 'genre']])\n",
    "\n",
    "# Validation\n",
    "predicted_interactions = model.predict(X_test).flatten()\n",
    "rmse = mean_squared_error(y_test, predicted_interactions, squared=False)\n",
    "print(\"RMSE for neural network predictions:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict interaction scores for all songs\n",
    "\n",
    "# print(\"starting prediction\") \n",
    "\n",
    "# predicted_scores = model.predict(spotify_features_scaled).flatten()\n",
    "# spotify_data['predicted_interaction'] = predicted_scores\n",
    "\n",
    "# # k-NN model using enhanced features\n",
    "# features_with_score = features + ['predicted_interaction']\n",
    "# knn = NearestNeighbors(n_neighbors=5, metric='euclidean')\n",
    "# knn.fit(spotify_data[features_with_score])\n",
    "\n",
    "# # Example user query using k-NN with neural network outputs\n",
    "# user_index = 3  # Change based on your user profile index\n",
    "# user_id = user_profiles.iloc[user_index]['userid']\n",
    "# user_top_genre = user_profiles.iloc[user_index]['genre']\n",
    "# user_feature_vector = user_features_scaled[user_index].reshape(1, -1)\n",
    "# user_predicted_score = model.predict(user_feature_vector).flatten()[0]\n",
    "# query_vector = np.append(user_feature_vector, user_predicted_score).reshape(1, -1)\n",
    "\n",
    "# # Finding top 5 nearest songs\n",
    "# distances, indices = knn.kneighbors(query_vector)\n",
    "# recommended_songs = spotify_data.iloc[indices[0]]\n",
    "\n",
    "# # Output recommended songs\n",
    "# print(f\"Recommended Songs for User: {user_id}, Top Genre: {user_top_genre}\")\n",
    "# print(recommended_songs[['track', 'artist', 'genre']])\n",
    "\n",
    "# # Validation\n",
    "# predicted_interactions = model.predict(X_test).flatten()\n",
    "# rmse = mean_squared_error(y_test, predicted_interactions, squared=False)\n",
    "# print(\"RMSE for neural network predictions:\", rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
