{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "# Load Data\n",
    "spotify_data = pd.read_csv('cleaned_spotify_data.csv')\n",
    "user_profiles = pd.read_csv('cleaned_user_profiles.csv')\n",
    "user_profiles = user_profiles.sample(frac = 0.1, random_state = 42)\n",
    "spotify_data = spotify_data.sample(frac = 0.25, random_state = 42)\n",
    "\n",
    "features = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "spotify_features = spotify_data[features]\n",
    "user_features = user_profiles[features]\n",
    "\n",
    "# Data Scaling\n",
    "scaler = StandardScaler()\n",
    "spotify_features_scaled = scaler.fit_transform(spotify_features)\n",
    "spotify_features_scaled = spotify_features_scaled\n",
    "user_features_scaled = scaler.transform(user_features)\n",
    "user_features_scaled = user_features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30056</th>\n",
       "      <td>I Miss You</td>\n",
       "      <td>Jeriqo</td>\n",
       "      <td>edm</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.717</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>174.026</td>\n",
       "      <td>216347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11827</th>\n",
       "      <td>Who Are You</td>\n",
       "      <td>The Who</td>\n",
       "      <td>rock</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.661</td>\n",
       "      <td>9</td>\n",
       "      <td>-11.405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>0.265000</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>156.371</td>\n",
       "      <td>378707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23571</th>\n",
       "      <td>Happy</td>\n",
       "      <td>The Beef Seeds</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.758</td>\n",
       "      <td>10</td>\n",
       "      <td>-5.204</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>86.529</td>\n",
       "      <td>218044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14741</th>\n",
       "      <td>ONE</td>\n",
       "      <td>Rev Theory</td>\n",
       "      <td>rock</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.966</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.352</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>90.016</td>\n",
       "      <td>208196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>Palace/Curse</td>\n",
       "      <td>The Internet</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.625</td>\n",
       "      <td>10</td>\n",
       "      <td>-8.212</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3230</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>67.104</td>\n",
       "      <td>440013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>Captain Save a Hoe (feat. The Click, D-Shot, B...</td>\n",
       "      <td>E-40</td>\n",
       "      <td>rap</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.514</td>\n",
       "      <td>7</td>\n",
       "      <td>-12.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2920</td>\n",
       "      <td>0.5630</td>\n",
       "      <td>166.015</td>\n",
       "      <td>287600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>Macarena - Bayside Boys Remix</td>\n",
       "      <td>Los Del Rio</td>\n",
       "      <td>pop</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.909</td>\n",
       "      <td>11</td>\n",
       "      <td>-6.032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>103.189</td>\n",
       "      <td>222027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23613</th>\n",
       "      <td>How Crazy Is That</td>\n",
       "      <td>Derrick Ryan</td>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.326</td>\n",
       "      <td>6</td>\n",
       "      <td>-12.198</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0754</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>123.940</td>\n",
       "      <td>193548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>Song To The Siren (Remastered)</td>\n",
       "      <td>This Mortal Coil</td>\n",
       "      <td>pop</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.240</td>\n",
       "      <td>10</td>\n",
       "      <td>-12.598</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>128.679</td>\n",
       "      <td>211093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30005</th>\n",
       "      <td>Where Is the Love (Wave Remix)</td>\n",
       "      <td>Alex Martura</td>\n",
       "      <td>edm</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.645</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.815</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>115.980</td>\n",
       "      <td>184138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8208 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   track            artist  \\\n",
       "30056                                         I Miss You            Jeriqo   \n",
       "11827                                        Who Are You           The Who   \n",
       "23571                                              Happy    The Beef Seeds   \n",
       "14741                                                ONE        Rev Theory   \n",
       "25570                                       Palace/Curse      The Internet   \n",
       "...                                                  ...               ...   \n",
       "7836   Captain Save a Hoe (feat. The Click, D-Shot, B...              E-40   \n",
       "764                        Macarena - Bayside Boys Remix       Los Del Rio   \n",
       "23613                                  How Crazy Is That      Derrick Ryan   \n",
       "3422                      Song To The Siren (Remastered)  This Mortal Coil   \n",
       "30005                     Where Is the Love (Wave Remix)      Alex Martura   \n",
       "\n",
       "      genre  danceability  energy  key  loudness  mode  speechiness  \\\n",
       "30056   edm         0.520   0.789    0    -7.717     1       0.0432   \n",
       "11827  rock         0.651   0.661    9   -11.405     1       0.0511   \n",
       "23571   r&b         0.640   0.758   10    -5.204     1       0.1600   \n",
       "14741  rock         0.398   0.966    4    -2.352     0       0.0453   \n",
       "25570   r&b         0.447   0.625   10    -8.212     0       0.3230   \n",
       "...     ...           ...     ...  ...       ...   ...          ...   \n",
       "7836    rap         0.753   0.514    7   -12.235     1       0.2600   \n",
       "764     pop         0.746   0.909   11    -6.032     1       0.0580   \n",
       "23613   r&b         0.782   0.326    6   -12.198     0       0.0754   \n",
       "3422    pop         0.216   0.240   10   -12.598     1       0.0406   \n",
       "30005   edm         0.793   0.645    2    -9.815     0       0.0443   \n",
       "\n",
       "       acousticness  instrumentalness  liveness  valence    tempo  duration_ms  \n",
       "30056      0.004910          0.000013    0.0816   0.4150  174.026       216347  \n",
       "11827      0.265000          0.003130    0.1060   0.4890  156.371       378707  \n",
       "23571      0.665000          0.000000    0.1270   0.9320   86.529       218044  \n",
       "14741      0.000006          0.000000    0.3030   0.5200   90.016       208196  \n",
       "25570      0.035100          0.000727    0.2430   0.2610   67.104       440013  \n",
       "...             ...               ...       ...      ...      ...          ...  \n",
       "7836       0.061200          0.000000    0.2920   0.5630  166.015       287600  \n",
       "764        0.206000          0.000002    0.0656   0.9620  103.189       222027  \n",
       "23613      0.058500          0.000009    0.1320   0.1970  123.940       193548  \n",
       "3422       0.843000          0.000006    0.1350   0.0875  128.679       211093  \n",
       "30005      0.531000          0.000210    0.1000   0.3650  115.980       184138  \n",
       "\n",
       "[8208 rows x 15 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34c5b62e9510fbf18271381aba7cf683\n"
     ]
    }
   ],
   "source": [
    "user_index = 4  # Change based on your user profile index\n",
    "user_id = user_profiles.iloc[user_index]['userid']\n",
    "\n",
    "print(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch processing... Total users: 1294, Total songs: 8208\n",
      "Processing batch from user index 0 to 99\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 100 to 199\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 200 to 299\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 300 to 399\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 400 to 499\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 500 to 599\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 600 to 699\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 700 to 799\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 800 to 899\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 900 to 999\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 1000 to 1099\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 1100 to 1199\n",
      "Feature similarity calculated for batch. Shape: (100, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Processing batch from user index 1200 to 1293\n",
      "Feature similarity calculated for batch. Shape: (94, 8208)\n",
      "Genre and artist similarity calculated for batch.\n",
      "Interaction scores updated for batch. Current shape of scores array: (1294, 8208)\n",
      "Garbage collection triggered after processing batch.\n",
      "Data prepared for neural network input.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gc  # Garbage Collector interface\n",
    "\n",
    "def calculate_interaction_batch(user_features_scaled, spotify_features_scaled, user_profiles, spotify_data, batch_size=100):\n",
    "    num_users = user_profiles.shape[0]\n",
    "    num_songs = spotify_data.shape[0]\n",
    "    interaction_scores = np.zeros((num_users, num_songs))\n",
    "    \n",
    "    print(f\"Starting batch processing... Total users: {num_users}, Total songs: {num_songs}\")\n",
    "\n",
    "    # Batch processing\n",
    "    for start_idx in range(0, num_users, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_users)\n",
    "        print(f\"Processing batch from user index {start_idx} to {end_idx - 1}\")\n",
    "\n",
    "        # Calculate distances and similarity scores for the batch\n",
    "        user_batch = user_features_scaled[start_idx:end_idx]\n",
    "        distances = np.sqrt(((user_batch[:, np.newaxis, :] - spotify_features_scaled[np.newaxis, :, :]) ** 2).sum(axis=2))\n",
    "        feature_similarity = np.exp(-distances)\n",
    "        print(f\"Feature similarity calculated for batch. Shape: {feature_similarity.shape}\")\n",
    "\n",
    "        # Calculate genre and artist similarity\n",
    "        genre_similarity = (user_profiles['genre'].values[start_idx:end_idx, np.newaxis] == spotify_data['genre'].values[np.newaxis, :]).astype(int)\n",
    "        artist_similarity = (user_profiles['artist'].values[start_idx:end_idx, np.newaxis] == spotify_data['artist'].values[np.newaxis, :]).astype(int)\n",
    "        print(f\"Genre and artist similarity calculated for batch.\")\n",
    "\n",
    "        # Calculate composite score for the batch\n",
    "        interaction_scores[start_idx:end_idx] = 0.7 * feature_similarity + 0.2 * genre_similarity + 0.1 * artist_similarity\n",
    "        print(f\"Interaction scores updated for batch. Current shape of scores array: {interaction_scores.shape}\")\n",
    "\n",
    "        # Explicitly call garbage collection\n",
    "        gc.collect()\n",
    "        print(f\"Garbage collection triggered after processing batch.\")\n",
    "\n",
    "    return interaction_scores\n",
    "\n",
    "# Usage example with debugging\n",
    "interaction_scores = calculate_interaction_batch(user_features_scaled, spotify_features_scaled, user_profiles, spotify_data, batch_size=100)\n",
    "interaction_threshold = np.percentile(interaction_scores, 75)  # top 25% as positive interaction\n",
    "interaction = (interaction_scores >= interaction_threshold).astype(int)\n",
    "\n",
    "# Flatten interaction matrix and features for neural network input\n",
    "X = spotify_features_scaled.repeat(len(user_profiles), axis=0)\n",
    "y = interaction.flatten()\n",
    "print(\"Data prepared for neural network input.\")\n",
    "\n",
    "# def calculate_interaction_vectorized(user_features_scaled, spotify_features_scaled, user_profiles, spotify_data):\n",
    "#     # Euclidean distances\n",
    "#     distances = np.sqrt(((user_features_scaled[:, np.newaxis, :] - spotify_features_scaled[np.newaxis, :, :]) ** 2).sum(axis=2))\n",
    "#     print(distances)\n",
    "#     # Scale distances into similarity scores (exp(-distance))\n",
    "#     feature_similarity = np.exp(-distances)\n",
    "#     print(feature_similarity)\n",
    "#     # Genre and artist similarity (binary 0 or 1)\n",
    "#     genre_similarity = (user_profiles['genre'].values[:, np.newaxis] == spotify_data['genre'].values[np.newaxis, :]).astype(int)\n",
    "#     print(genre_similarity)\n",
    "#     artist_similarity = (user_profiles['artist'].values[:, np.newaxis] == spotify_data['artist'].values[np.newaxis, :]).astype(int)\n",
    "#     print(artist_similarity)\n",
    "    \n",
    "#     # Composite score\n",
    "#     interaction_scores = 0.7 * feature_similarity + 0.2 * genre_similarity + 0.1 * artist_similarity\n",
    "#     print(interaction_scores)\n",
    "#     return interaction_scores\n",
    "\n",
    "# # Generate interaction scores\n",
    "# interaction_scores = calculate_interaction_vectorized(user_features_scaled, spotify_features_scaled, user_profiles, spotify_data)\n",
    "# interaction_threshold = np.percentile(interaction_scores, 75)  # top 25% as positive interaction\n",
    "# interaction = (interaction_scores >= interaction_threshold).astype(int)\n",
    "\n",
    "# # Flatten interaction matrix and features for neural network input\n",
    "# X = spotify_features_scaled.repeat(len(user_profiles), axis=0)\n",
    "# y = interaction.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1609s\u001b[0m 6ms/step - accuracy: 0.7494 - loss: 0.5874 - val_accuracy: 0.7497 - val_loss: 0.5658 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1495s\u001b[0m 6ms/step - accuracy: 0.7502 - loss: 0.5653 - val_accuracy: 0.7497 - val_loss: 0.5658 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1446s\u001b[0m 5ms/step - accuracy: 0.7501 - loss: 0.5654 - val_accuracy: 0.7497 - val_loss: 0.5657 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1591s\u001b[0m 6ms/step - accuracy: 0.7500 - loss: 0.5654 - val_accuracy: 0.7497 - val_loss: 0.5658 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1318s\u001b[0m 5ms/step - accuracy: 0.7500 - loss: 0.5655 - val_accuracy: 0.7497 - val_loss: 0.5658 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2163s\u001b[0m 8ms/step - accuracy: 0.7500 - loss: 0.5655 - val_accuracy: 0.7497 - val_loss: 0.5659 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1378s\u001b[0m 5ms/step - accuracy: 0.7503 - loss: 0.5651 - val_accuracy: 0.7497 - val_loss: 0.5657 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m881s\u001b[0m 3ms/step - accuracy: 0.7499 - loss: 0.5655 - val_accuracy: 0.7497 - val_loss: 0.5658 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m804s\u001b[0m 3ms/step - accuracy: 0.7499 - loss: 0.5630 - val_accuracy: 0.7497 - val_loss: 0.5632 - learning_rate: 2.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m899s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.5630 - val_accuracy: 0.7497 - val_loss: 0.5632 - learning_rate: 2.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m894s\u001b[0m 3ms/step - accuracy: 0.7503 - loss: 0.5626 - val_accuracy: 0.7497 - val_loss: 0.5632 - learning_rate: 2.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m265529/265529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m641s\u001b[0m 2ms/step - accuracy: 0.7499 - loss: 0.5630 - val_accuracy: 0.7497 - val_loss: 0.5633 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m 91283/265529\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:07\u001b[0m 4ms/step - accuracy: 0.7500 - loss: 0.5630"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Fitting the model\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:316\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    314\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m--> 316\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\callbacks\\callback_list.py:103\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    101\u001b[0m         callback\u001b[38;5;241m.\u001b[39mon_train_batch_begin(batch, logs\u001b[38;5;241m=\u001b[39mlogs)\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    104\u001b[0m     logs \u001b[38;5;241m=\u001b[39m logs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Neural network setup with Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=X_train.shape[1], kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001, clipnorm=1.0)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), \n",
    "          callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict interaction scores for all songs using batch prediction\n",
    "predicted_scores = model.predict(spotify_features_scaled).flatten()\n",
    "spotify_data['predicted_interaction'] = predicted_scores\n",
    "gc.collect()  # Clear memory of no longer needed large objects\n",
    "print(\"prediction complete and memory cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-NN model using enhanced features\n",
    "features_with_score = features + ['predicted_interaction']\n",
    "knn = NearestNeighbors(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(spotify_data[features_with_score])\n",
    "print(\"k-NN model set up.\")\n",
    "\n",
    "user_index = 3  # Change based on your user profile index\n",
    "user_id = user_profiles.iloc[user_index]['userid']\n",
    "user_top_genre = user_profiles.iloc[user_index]['genre']\n",
    "user_feature_vector = user_features_scaled[user_index].reshape(1, -1)\n",
    "user_predicted_score = model.predict(user_feature_vector).flatten()[0]\n",
    "query_vector = np.append(user_feature_vector, user_predicted_score).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding top 5 nearest songs\n",
    "distances, indices = knn.kneighbors(query_vector)\n",
    "recommended_songs = spotify_data.iloc[indices[0]]\n",
    "\n",
    "# Output recommended songs\n",
    "print(f\"Recommended Songs for User: {user_id}, Top Genre: {user_top_genre}\")\n",
    "print(recommended_songs[['track', 'artist', 'genre']])\n",
    "\n",
    "# Validation\n",
    "predicted_interactions = model.predict(X_test).flatten()\n",
    "rmse = mean_squared_error(y_test, predicted_interactions, squared=False)\n",
    "print(\"RMSE for neural network predictions:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict interaction scores for all songs\n",
    "\n",
    "# print(\"starting prediction\") \n",
    "\n",
    "# predicted_scores = model.predict(spotify_features_scaled).flatten()\n",
    "# spotify_data['predicted_interaction'] = predicted_scores\n",
    "\n",
    "# # k-NN model using enhanced features\n",
    "# features_with_score = features + ['predicted_interaction']\n",
    "# knn = NearestNeighbors(n_neighbors=5, metric='euclidean')\n",
    "# knn.fit(spotify_data[features_with_score])\n",
    "\n",
    "# # Example user query using k-NN with neural network outputs\n",
    "# user_index = 3  # Change based on your user profile index\n",
    "# user_id = user_profiles.iloc[user_index]['userid']\n",
    "# user_top_genre = user_profiles.iloc[user_index]['genre']\n",
    "# user_feature_vector = user_features_scaled[user_index].reshape(1, -1)\n",
    "# user_predicted_score = model.predict(user_feature_vector).flatten()[0]\n",
    "# query_vector = np.append(user_feature_vector, user_predicted_score).reshape(1, -1)\n",
    "\n",
    "# # Finding top 5 nearest songs\n",
    "# distances, indices = knn.kneighbors(query_vector)\n",
    "# recommended_songs = spotify_data.iloc[indices[0]]\n",
    "\n",
    "# # Output recommended songs\n",
    "# print(f\"Recommended Songs for User: {user_id}, Top Genre: {user_top_genre}\")\n",
    "# print(recommended_songs[['track', 'artist', 'genre']])\n",
    "\n",
    "# # Validation\n",
    "# predicted_interactions = model.predict(X_test).flatten()\n",
    "# rmse = mean_squared_error(y_test, predicted_interactions, squared=False)\n",
    "# print(\"RMSE for neural network predictions:\", rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
