# Personalized Music Discovery Artificial Neural Network Project
Group Project for CS/ME/ECE 539

## Group Members
- Arushi Renschler Pandey
- Nicolas Ruffolo
- Allen Chien

## Introduction
This project is supposed to build a song recommendation system soley based on a generated user profile and a library of 30,000 Spotify songs. The library of songs is a pool of songs that our various methods of recommendation attempt to pull from to match to the user's profile.

## 30K Spotify Songs
This dataset was found on Kaggle and contained 30,000 songs and associated audio features generated from Kaggle. 

## User Profile Generation
The profiles were generated from a 1.2GB dataset of playlist data from Kaggle. This only included the artist name and the track name. The Spotify API was used to populate this dataset with audio features so it will be able match the 30k dataset so there will be optimal prediction. We distilled down user's playlists by averaging all numerical characteristics, and calculated the mode of all string characters to see which artist appears the most. This results in a profile that we hope accurately reflects the user's preferences.

## Method 1 -> Branch "Method-1"
In our initial approach, we employ an autoencoder to learn the information bottleneck of the feature vector. Subsequently, we utilize K Nearest Neighbor to cluster the data points, aiming to output songs that are the closest neighbors based on the input. However, we encountered a challenge wherein using the information bottleneck to train a clustering algorithm proved suboptimal. The information bottleneck transforms all inputs into a linear shape rather than circling data points, hindering our ability to identify the closest neighbors effectively. This model was abandoned as it had no real utility or accurate results. For our second attempt, we recognized the potential of genre as a valuable decision factor in song recommendations. Consequently, we opted to generate labels based on the input genre, randomly selecting two songs from the same genre for each genre category. The song names and genres were then encoded using label encoding, converting them into integers. 

Our first successful model in this iteration was developed using multi-layer perceptrons, incorporating multiple dense layers along with batch normalization layers. The input vector, comprising both audio features and genre, was fed into the model, which produced two distinct integers as output. These integers were subsequently passed into a K-nearest neighbor model that we had previously trained to cluster all the distinct songs. The model then outputted the two closest values, which were decoded back into song names.

For predictions, drawing inspiration from the Skip-Gram Model, we averaged all the features per song for each user. These averaged features were then fed into the model to obtain two recommended songs.

In the results of our first model, as depicted in Figure 3, we attained a 50% accuracy rate after 100 epochs of training. After observing a continual decrease in model loss, it became apparent that the model was underfitting. Despite our efforts to deepen the model and employ various techniques to prevent overfitting, such as regularization methods or dropout layers, the model's performance did not improve significantly. This suggests that there may be limitations in the representational capacity of the model or issues with the complexity of the task at hand. Further investigation into model architecture and training strategies may be necessary to address these challenges effectively.

## Method 2 -> Branch "Method-2"
Model II was an attempt to use simulated interaction data, a sequential Neural Network, and then a stacked ensemble KNN Clustering layer. The Dataset 1 and Dataset 2 were cleaned to ensure that there were no duplicates and genre matching. After this, all numerical features were selected. This simulated interaction data was generated by computing interaction scores between users and songs by processing user profiles and song features in batches. Steps for the interaction score calculation are listed below:

Computes Euclidean distances between each user in the batch and all songs, then converts these distances to a similarity score using an exponential function.
Compares genres and artists directly to generate similarity scores, assuming a match returns 1 (true) and no match returns 0 (false).
Calculates a final interaction score as a weighted sum of feature, genre, and artist similarities. Highest weights were assigned to the genre, feature and then artist. 

The interaction score had to be calculated in batches due to the intensive memory used during this process. These interaction scores were then processed to create a threshold for positive interaction (top 25% of all interaction scores). The interaction features were flattened to create a “y” for neural network training. This gives us a method of recommending songs that have a positive interaction. The X is the Spotify song bank features that are scaled and trimmed to the length of the user profiles. This is then fed into a Sequential neural network which is trained on user profiles, and song bank features. These predictions are made to score the interactions and verify accuracy with the user’s profile. 

After this, the code uses a k-Nearest Neighbors (k-NN) model to recommend songs by identifying the closest matches to a user's profile within the feature space. After defining relevant song characteristics and user preferences as features, and scaling them for normalization, the k-NN algorithm is applied to the enhanced feature set. The system calculates the Euclidean distance between the user's feature vector and all songs in the dataset, selecting the nearest songs based on these distances. This approach effectively tailors song recommendations to align with the user’s specific musical tastes and preferences, leveraging both the descriptive song attributes and user data.

Our result for Model II resulted in higher accuracy than Model I (as depicted in ; however, there was a relatively stagnant accuracy and loss; which means that the model is not learning as designed. The model's accuracy starts at about 74.99% and shows slight improvements over the epochs, peaking at 75.05% in the ninth epoch. The loss, which measures how well the model's predictions match the actual data, starts at 0.5633 and decreases slightly to 0.5615 by the final epoch, suggesting that the model is learning and improving its prediction accuracy over time. Validation accuracy remains consistent at 74.95% across all epochs, indicating that the model generalizes well on unseen data. The relatively stable validation accuracy also suggests that the model is neither overfitting nor underfitting. 

The resulting predictions however didn’t align very well with expected weights on genre; however, due to the nuanced art of genre assignment, these songs may be still enjoyable by the user. These relatively unexpected results pushed us to pursue other avenues of improvement and modeling. In addition, the model had incredibly high computing demands which made it incredibly difficult to make adjustments to. We utilized all of our computing credits on both Google Colab and Google Cloud Platform. After this, we turned to utilizing computers with advanced Graphic Processing Units. While making modifications however, we noticed that no matter what we changed in terms of model structure, data preprocessing, and feature engineering, the accuracy hovered around 75% and remained the same with loss. 

## Method 3 -> Branch "Method-3"
This model is a KNN model made from the sklearn machine learning package. The data is first cleaned by removing duplicate tracks, and relevant musical features like danceability, energy, and loudness are extracted and standardized to ensure uniformity in scale. We then implement a custom distance function that prioritizes genre compatibility by imposing a high penalty for genre mismatches, alongside calculating the Euclidean distance for other features. By mapping genres to numeric values, we incorporate them into our KNN model to make personalized song recommendations for each user. 

This model was posed as the simplest alternative to all the other models. It can often be true that a simpler solution can be better than more complicated ones. This is the simplest form of prediction and provides a clean output which has aligned with the expectations that we have. 

The resulting output is in a relatively short Euclidean distance between the user and their recommended songs. All of the genre’s of the recommended songs align with the user’s preference and seem to fit in their current profile. The previous iterations that excluded the genre as a prime choice characteristic resulted in songs that were completely unrelated. For example, a user with a heavily EDM skewed profile, would be recommended rock songs since they have similar features in terms of loudness and energy. This is not an intended result as user’s who prefer EDM would likely not enjoy rock music. 
